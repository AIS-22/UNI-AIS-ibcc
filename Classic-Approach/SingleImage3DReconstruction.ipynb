{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import transform\n",
    "from shapely.geometry import LineString\n",
    "from stl import mesh"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Plot image and load calibration parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_points, image_points, ret, k_matrix, distortion, r_vecs, t_vecs = np.load(\n",
    "    \"Calibration/cam_parameters_iPhone8.npy\", allow_pickle=True)\n",
    "\n",
    "# Load the image and undistort it using the calibration parameters\n",
    "imageName = 'images/book.JPG'\n",
    "image = cv2.imread(imageName)\n",
    "undistorted_image = cv2.undistort(image, k_matrix, distortion)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "axs[0].set_axis_off()\n",
    "axs[1].set_axis_off()\n",
    "axs[0].imshow(image, aspect='auto')\n",
    "axs[1].imshow(undistorted_image, aspect=\"auto\")\n",
    "axs[0].set_title(\"image\")\n",
    "axs[1].set_title(\"undistorted image\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw detected lines of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imageWithEdges = undistorted_image\n",
    "gray = cv2.cvtColor(imageWithEdges, cv2.COLOR_RGB2GRAY)\n",
    "#find optimum parameters for canny (edge detection)\n",
    "v = np.mean(gray)\n",
    "sigma = 0.33\n",
    "cannyTh1 = int(max(0, (1.0 - sigma) * v))\n",
    "cannyTh2 = int(min(255, (1.0 + sigma) * v))\n",
    "edges = cv2.Canny(gray, cannyTh1, cannyTh2)\n",
    "\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 180, 30, maxLineGap=2500)\n",
    "whiteImage = np.full((imageWithEdges.shape[0], imageWithEdges.shape[1], imageWithEdges.shape[2]), 255, dtype=np.uint8)\n",
    "\n",
    "for line in lines:\n",
    "    x1, y1, x2, y2 = line[0]\n",
    "    cv2.line(imageWithEdges, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    cv2.line(whiteImage, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "fig.suptitle(\"canny thresholds = \" + str(cannyTh1) + \" , \" + str(cannyTh2))\n",
    "axs[0].set_axis_off()\n",
    "axs[0].imshow(imageWithEdges, aspect='auto')\n",
    "axs[1].imshow(whiteImage, aspect=\"auto\")\n",
    "axs[0].set_title(\"image with hough lines\")\n",
    "axs[1].set_title(\"houghlines\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Getting lines by help of user input\n",
    "\n",
    "#### As you can see the houghline algorithm can not detect perfectly the edges of the book. Therefore, a user input is needed. With the help of the functions below, the user can select and delete lines in the image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def detect_lines(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #find optimum parameters for canny (edge detection)\n",
    "    v = np.mean(gray)\n",
    "    sigma = 0.33\n",
    "    cannyTh1 = int(max(0, (1.0 - sigma) * v))\n",
    "    cannyTh2 = int(min(255, (1.0 + sigma) * v))\n",
    "    edges = cv2.Canny(gray, cannyTh1, cannyTh2)\n",
    "\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi / 180.0, 120, np.array([]))\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_line_starting_points(tuple):\n",
    "    x1, y1 = tuple[0]\n",
    "    x2, y2 = tuple[1]\n",
    "\n",
    "    # Calculate the slope\n",
    "    slope = (y2 - y1) / (x2 - x1)\n",
    "\n",
    "    # Calculate the y-intercept\n",
    "    y_intercept = y1 - slope * x1\n",
    "\n",
    "    #extend the line\n",
    "    x1 = x1 * -1000\n",
    "    y1 = np.int32(slope * x1 + y_intercept)\n",
    "    x2 = x2 * 1000\n",
    "    y2 = np.int32(slope * x2 + y_intercept)\n",
    "\n",
    "    return ((x1, y1), (x2, y2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "\n",
    "\n",
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    # if the left mouse button is clicked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # append the coordinates of the clicked point to the list\n",
    "        points.append((x, y))\n",
    "\n",
    "\n",
    "def draw_lines_manually(lines):\n",
    "    points.clear()\n",
    "    print(\"Do you want to add a new line? (y/n)\")\n",
    "    if input() == 'y':\n",
    "        #print the image and let the user click on the position. The user should select points which gets then appended as a tuple to lines\n",
    "        # Create a window to display the image\n",
    "        cv2.namedWindow('image')\n",
    "\n",
    "        # Set the mouse callback function for the window\n",
    "        cv2.setMouseCallback('image', on_mouse_click)\n",
    "\n",
    "        while True:\n",
    "            # Display the image in a new window\n",
    "            cv2.imshow('image', imageWithEdgesOptimized)\n",
    "\n",
    "            # Check if the user pressed the 'q' key or already 2 points selected\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q') or len(points) == 2:\n",
    "                break\n",
    "\n",
    "        # Destroy the window and exit the program\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        x1, y1 = points[0]\n",
    "        x2, y2 = points[1]\n",
    "\n",
    "        temp = imageWithEdgesOptimized.copy()\n",
    "        #let user check if he/she wants to keep the line\n",
    "        cv2.line(temp, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        plt.imshow(temp)\n",
    "        #wait 2 seconds\n",
    "        plt.pause(2)\n",
    "        plt.close()\n",
    "        print(\"Do you want to keep this line? (y/n)\")\n",
    "        if input() == 'y':\n",
    "            ((x1, y1), (x2, y2)) = extend_line_starting_points(((x1, y1), (x2, y2)))\n",
    "            cv2.line(imageWithEdgesOptimized, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "            print(\"To which axis does the line correspond? (x/y/z)\")\n",
    "            answer = input()\n",
    "            if answer == 'x':\n",
    "                lines['x'].append(((x1, y1), (x2, y2)))\n",
    "            if answer == 'y':\n",
    "                lines['y'].append(((x1, y1), (x2, y2)))\n",
    "            if answer == 'z':\n",
    "                lines['z'].append(((x1, y1), (x2, y2)))\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(imageName)\n",
    "lines = detect_lines(image)\n",
    "imageWithEdgesOptimized = image.copy()\n",
    "\n",
    "#save all lines in a map\n",
    "#declare an axis dictionary to store the start and end points of the lines\n",
    "lineStartEndPointsAxisMap = {'x': [], 'y': [], 'z': []}\n",
    "\n",
    "for line in lines:\n",
    "    rho, theta = line[0]\n",
    "    a = np.cos(theta)\n",
    "    b = np.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "    x1 = int(x0 + 10000 * (-b))\n",
    "    y1 = int(y0 + 10000 * (a))\n",
    "    x2 = int(x0 - 10000 * (-b))\n",
    "    y2 = int(y0 - 10000 * (a))\n",
    "    temp = image.copy()\n",
    "    #let user check if he/she wants to keep the line\n",
    "    cv2.line(temp, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "    plt.imshow(temp)\n",
    "    #wait 1 second\n",
    "    plt.pause(1)\n",
    "    plt.close()\n",
    "    print(\"Do you want to keep this line? (y/n)\")\n",
    "    if input() == 'y':\n",
    "        cv2.line(imageWithEdgesOptimized, (x1, y1), (x2, y2), (0, 255, 0), 1)\n",
    "        print(\"To which axis does the line correspond? (x/y/z)\")\n",
    "        answer = input()\n",
    "        if answer == 'x':\n",
    "            lineStartEndPointsAxisMap['x'].append(((x1, y1), (x2, y2)))\n",
    "        if answer == 'y':\n",
    "            lineStartEndPointsAxisMap['y'].append(((x1, y1), (x2, y2)))\n",
    "        if answer == 'z':\n",
    "            lineStartEndPointsAxisMap['z'].append(((x1, y1), (x2, y2)))\n",
    "\n",
    "while draw_lines_manually(lineStartEndPointsAxisMap):\n",
    "    pass\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 3))\n",
    "axs[0].set_axis_off()\n",
    "axs[1].set_axis_off()\n",
    "axs[0].imshow(imageWithEdges, aspect='auto')\n",
    "axs[1].imshow(imageWithEdgesOptimized, aspect=\"auto\")\n",
    "axs[0].set_title(\"image with detected lines\")\n",
    "axs[1].set_title(\"image with optimized detected lines\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As a result we get the exact lines, which are needed for the 3D reconstruction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result of line detection by user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extendedLines = image.copy()\n",
    "#loop throw map and draw lines in image to check the result\n",
    "for key, element in lineStartEndPointsAxisMap.items():\n",
    "    for e in element:\n",
    "        cv2.line(extendedLines, e[0], e[1], (0, 255, 0), 1)\n",
    "\n",
    "plt.imshow(extendedLines, aspect=\"auto\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Determine Vanishing Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vanishingPoints = {'x': (), 'y': (), 'z': ()}\n",
    "\n",
    "for key, element in lineStartEndPointsAxisMap.items():\n",
    "    #calculate the intersection of the first 2 lines (the others should also intersect at the same point)\n",
    "    t1 = element[0]\n",
    "    t2 = element[1]\n",
    "    #create two lines\n",
    "    line1 = LineString(t1)\n",
    "    line2 = LineString(t2)\n",
    "    vanishingPoints[key] = line1.intersection(line2).x, line1.intersection(line2).y\n",
    "\n",
    "print('calculated vanishing points:')\n",
    "print(vanishingPoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "#### Try to automatically transform the objects planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Algorithm from https://kusemanohar.wordpress.com/2014/03/18/3d-reconstruction-with-single-view/\n",
    "\n",
    "#form the projection matrix\n",
    "vx = np.array([vanishingPoints['x'][0], vanishingPoints['x'][1], 1])\n",
    "vy = np.array([vanishingPoints['y'][0], vanishingPoints['y'][1], 1])\n",
    "vz = np.array([vanishingPoints['z'][0], vanishingPoints['z'][1], 1])\n",
    "w = np.array([0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# World Origin in im-cords\n",
    "WO = np.array([55, 195, 1])\n",
    "# Reference axis-cords in im-cords\n",
    "ref_x = np.array([529, 159, 1])\n",
    "ref_y = np.array([423, 351, 1])\n",
    "ref_z = np.array([293, 165, 1])\n",
    "# Reference axis distances in pixels\n",
    "ref_x_dis = 46\n",
    "ref_y_dis = 205\n",
    "ref_z_dis = 266\n",
    "# Scaling factors of the projection matrix using the least squares solution\n",
    "a_x = np.linalg.lstsq(vx.reshape(-1, 1), (ref_x - WO), rcond=None)[0] / ref_x_dis\n",
    "a_y = np.linalg.lstsq(vy.reshape(-1, 1), (ref_y - WO), rcond=None)[0] / ref_y_dis\n",
    "a_z = np.linalg.lstsq(vz.reshape(-1, 1), (ref_z - WO), rcond=None)[0] / ref_z_dis\n",
    "# Construction of Projection Matrix\n",
    "projectionMatrix = np.column_stack([vx * a_x, vy * a_y, vz * a_z, WO])\n",
    "\n",
    "print(projectionMatrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform the image to the objects  normal planes using the projection matrix\n",
    "temp = projectionMatrix[:, [0, 1, 3]]\n",
    "new_Image = cv2.warpPerspective(image, temp, image.shape[:2])\n",
    "\n",
    "plt.imshow(new_Image, cmap='gray')\n",
    "plt.title('Try to map image to xy-plane')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "As we can see this approach was not successful, so let's determine the edges and transform the planes to rectangular images manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---\n",
    "### Manually transform object in the image to its planes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate the edge lengths of the object\n",
    "z_length = np.ceil(np.linalg.norm(np.array([195, 557]) - np.array([165, 293])))\n",
    "# x, y ,z from measurement of the real object\n",
    "ratios = [0.204, 0.714, 1]\n",
    "y_length = z_length * ratios[1]\n",
    "x_length = z_length * ratios[0]\n",
    "print(x_length)\n",
    "print(y_length)\n",
    "print(z_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transform and plot the YZ plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = image.copy()\n",
    "#source coordinates (edges in the image)\n",
    "src = np.array([165, 293,\n",
    "                413, 161,\n",
    "                351, 423,\n",
    "                195, 557, ]).reshape((4, 2))\n",
    "#destination coordinates (rectangular shape of the corresponding plane, manually calculated from the lengths)\n",
    "dst = np.array([165, 161,\n",
    "                355, 161,\n",
    "                355, 427,\n",
    "                165, 427]).reshape((4, 2))\n",
    "#using skimage’s transform module where ‘projective’ is our desired parameter\n",
    "tform = transform.estimate_transform('projective', src, dst)\n",
    "tf_img = transform.warp(trans, tform.inverse)\n",
    "\n",
    "yz_plane = tf_img[161:427, 165:355]\n",
    "\n",
    "plt.imshow(yz_plane)\n",
    "plt.axis(False)\n",
    "cv2.imwrite('object_images/yz_plane.png', 255 * yz_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transform and plot the XY plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = image.copy()\n",
    "#source coordinates (edges in the image)\n",
    "src = np.array([91, 253,\n",
    "                329, 123,\n",
    "                413, 161,\n",
    "                165, 293, ]).reshape((4, 2))\n",
    "#destination coordinates (rectangular shape of the corresponding plane, manually calculated from the lengths)\n",
    "dst = np.array([91, 123,\n",
    "                281, 110,\n",
    "                281, 180,\n",
    "                91, 178, ]).reshape(\n",
    "    (4, 2))\n",
    "#using skimage’s transform module where ‘projective’ is our desired parameter\n",
    "tform = transform.estimate_transform('projective', src, dst)\n",
    "tf_img = transform.warp(trans, tform.inverse)\n",
    "\n",
    "xy_plane = tf_img[110:180, 91:281]\n",
    "\n",
    "plt.imshow(xy_plane)\n",
    "plt.axis(False)\n",
    "cv2.imwrite('object_images/xy_plane.png', 255 * xy_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Transform and plot the XZ plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = image.copy()\n",
    "#source coordinates (edges in the image)\n",
    "src = np.array([91, 253,\n",
    "                165, 293,\n",
    "                195, 557,\n",
    "                159, 529, ]).reshape((4, 2))\n",
    "#destination coordinates (rectangular shape of the corresponding plane, manually calculated from the lengths)\n",
    "dst = np.array([91, 255,\n",
    "                146, 253,\n",
    "                146, 500,\n",
    "                100, 519, ]).reshape(\n",
    "    (4, 2))\n",
    "#using skimage’s transform module where ‘projective’ is our desired parameter\n",
    "tform = transform.estimate_transform('projective', src, dst)\n",
    "tf_img = transform.warp(trans, tform.inverse)\n",
    "\n",
    "xz_plane = tf_img[253:519, 91:146]\n",
    "\n",
    "plt.imshow(xz_plane)\n",
    "plt.axis(False)\n",
    "cv2.imwrite('object_images/xz_plane.png', 255 * xz_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Form a stl object with the corresponding plane pixel values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the 8 vertices of the cube\n",
    "vertices = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [+55, -1, -1],\n",
    "    [+55, +190, -1],\n",
    "    [-1, +190, -1],\n",
    "    [-1, -1, +266],\n",
    "    [+55, -1, +266],\n",
    "    [+55, +190, +266],\n",
    "    [-1, +190, +266]])\n",
    "# Define the 12 triangles composing the cube\n",
    "faces = np.array([\n",
    "    [0, 3, 1],\n",
    "    [1, 3, 2],\n",
    "    [0, 4, 7],\n",
    "    [0, 7, 3],\n",
    "    [4, 5, 6],\n",
    "    [4, 6, 7],\n",
    "    [5, 1, 2],\n",
    "    [5, 2, 6],\n",
    "    [2, 3, 6],\n",
    "    [3, 7, 6],\n",
    "    [0, 1, 5],\n",
    "    [0, 5, 4]])\n",
    "\n",
    "# Create the mesh\n",
    "cube = mesh.Mesh(np.zeros(faces.shape[0], dtype=mesh.Mesh.dtype))\n",
    "for i, f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        cube.vectors[i][j] = vertices[f[j], :]\n",
    "\n",
    "# Write the mesh to file \"cube.stl\"\n",
    "cube.save('cube.stl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Demonstrate distortion of view mapping if object on another object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def on_mouse_click(event, x, y, flags, param):\n",
    "    # if the left mouse button is clicked\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        # append the coordinates of the clicked point to the list\n",
    "        points.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#again just let the user determine the lines manually\n",
    "imageName = 'images/book_plug.png'\n",
    "image = cv2.imread(imageName)\n",
    "image = cv2.resize(image, (511, 688))\n",
    "trans = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(trans)\n",
    "plt.axis(False)\n",
    "plt.show()\n",
    "\n",
    "#declare an axis dictionary to store the start and end points of the lines\n",
    "dummyAxisMap = {'x': [], 'y': [], 'z': []}\n",
    "points = []\n",
    "\n",
    "#just a loop to determine the points of xy-plane\n",
    "# Create a window to display the image\n",
    "cv2.namedWindow('image')\n",
    "\n",
    "# Set the mouse callback function for the window\n",
    "cv2.setMouseCallback('image', on_mouse_click)\n",
    "\n",
    "while True:\n",
    "    # Display the image in a new window\n",
    "    cv2.imshow('image', image)\n",
    "\n",
    "    # Check if the user pressed the 'q' key or already 2 points selected\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q') or len(points) == 2:\n",
    "        break\n",
    "\n",
    "# Destroy the window and exit the program\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "#source coordinates (edges in the image)\n",
    "#y:len = 303 pixels and x_len according to ratio is 216 pixel\n",
    "src = np.array([30, 345,\n",
    "                304, 217,\n",
    "                474, 297,\n",
    "                174, 509, ]).reshape((4, 2))\n",
    "#destination coordinates (rectangular shape of the corresponding plane, manually calculated from the lengths)\n",
    "dst = np.array([30, 217,\n",
    "                333, 217,\n",
    "                333, 433,\n",
    "                30, 433, ]).reshape(\n",
    "    (4, 2))\n",
    "#using skimage’s transform module where ‘projective’ is our desired parameter\n",
    "tform = transform.estimate_transform('projective', src, dst)\n",
    "tf_img = transform.warp(trans, tform.inverse)\n",
    "\n",
    "xy_plane = tf_img[217:433, 30:333]\n",
    "\n",
    "plt.imshow(xy_plane)\n",
    "plt.axis(False)\n",
    "plt.title('Visualization of Object Distortion')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
