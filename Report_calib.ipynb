{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Image 3D reconstruction\n",
    "\n",
    "by Michael Hafner, Moritz Langer, Aleksandar Radovic\n",
    "\n",
    "## Responsibilities\n",
    "\n",
    " Classical Approach | Deep Learning Approach\n",
    " -------- | --------\n",
    " Michael Hafner   | Moritz Langer\n",
    " Aleksandar Radovic |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "To create 3D images out of 2D images stereovision is usually used. Therefore two images are needed to create a disparity map. With the help of the disparity map the 3D reconstruction can be developed. But what if you only have one camera and one image? Is it still possible to get a 3D image? \n",
    "\n",
    "This question is been analyzed by Michael Hafner, Moritz Langer and Aleksandar Radovic in this project. A single 3D reconstruction can be done with the help of a neural network or without. Both approaches were developed in this project. \n",
    "\n",
    "First the classical approach tries to get a 3D image with the help of the vanishing lines of the image. This approach has a lot of limitations which are shown below. To remove this limitations, the second part develops a neural network to achieve the goal of a single image 3D reconstruction. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Approach\n",
    "\n",
    "The classic approach uses just vanishing lines and vanishing points to reconstruct the image.\n",
    "* **Vanishing-Points:** Are points where the extended edge lines of an objectÂ´s dimension intersect.\n",
    "* **Vanishing_Lines:** Are lines which connect vanishing points of all 3 dimensions.\n",
    "This information can be used to extract information about the alignment (translation and rotation) of the given object in the image.\n",
    "This chapter explains how we developed our classic 3D reconstruction pipeline from camera calibration to the 3D object shown with Blender.\n",
    "\n",
    "### Camera Calibration (done by Michael Hafner)\n",
    "Since a camera ex- and intrinsics distort the image, in this project camera calibration was needed to remove those distortions.\n",
    "The  used code for camera calibration got adapted directly from *OpenCV*. To determine the parameters of the camera the following steps are necessary:\n",
    "1. Generate a checkerboard patter by using the *gen_pattern.py* file, provided in the Calibration folder.\n",
    "    * *python gen_pattern.py -o chessboard.svg --rows 10 --columns 7 --type checkerboard --square_size 20*\n",
    "    The amount of rows and columns declares the number of checker (white and black). The svg file than gets stored to the under *-o* declared path.\n",
    "2. Print out the checkerboard pattern and stick it to a plain and stiff surface. Otherwise, possible curvatures distort the determined parameters of the algorithm.\n",
    "3. Place the camera on its position where also the object gets photographed and take multiple images (angles) of the checkerboard. The more images, the more precise the results will become.\n",
    "4. After that, execute the notebook *CamCalibration.ipynb*\n",
    "    * The algorithm behind detects the edges where the black checker 'touch' each other.\n",
    "    * With that and the information of the size of the checker in the real world it is possible to map the 3D real world checker in the 2D image plane and determine the camera parameters from the known dimensions of the calibration pattern.\n",
    "5. This parameter then get stored in a numpy object/file to can be later used to undistort the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The following image shows the output of the calibration step, where the edges of the checker got detected by the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/cal.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/cal.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
