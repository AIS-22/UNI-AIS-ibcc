{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3D Reconstruction (done by Michael Hafner)\n",
    "\n",
    "After the extended lines of the object got determined it is possible now to calculate the intersections of those lines which provide the vanishing points.\n",
    "\n",
    "With this information an algorithm from https://kusemanohar.wordpress.com/2014/03/18/3d-reconstruction-with-single-view/ got used to determine the projection matrix. With that matrix it should be possible to get the projection of each plane. As you can see in the following image, the algorithm failed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/failed-transformation.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/failed-transformation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Since it was not possible to project the planes automatically using the above mentioned algorithm and finding or come up with another solution, a manual approach got used.\n",
    "With it first all side lengths of the object need to get measured to determine the ratios of the edge. After that the position (x-y values in the image) of every vertex got detected. The following code shows the transformation from the camera view to the plane view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trans = image.copy()\n",
    "#source coordinates (edges in the image)\n",
    "src = np.array([165, 293,\n",
    "                413, 161,\n",
    "                351, 423,\n",
    "                195, 557, ]).reshape((4, 2))\n",
    "#destination coordinates (rectangular shape of the corresponding plane, manually calculated from the lengths)\n",
    "dst = np.array([165, 161,\n",
    "                355, 161,\n",
    "                355, 427,\n",
    "                165, 427]).reshape((4, 2))\n",
    "#using skimage’s transform module where ‘projective’ is our desired parameter\n",
    "tform = transform.estimate_transform('projective', src, dst)\n",
    "tf_img = transform.warp(trans, tform.inverse)\n",
    "\n",
    "yz_plane = tf_img[161:427, 165:355]\n",
    "\n",
    "plt.imshow(yz_plane)\n",
    "plt.axis(False)\n",
    "cv2.imwrite('object_images/yz_plane.png', 255 * yz_plane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "The source coordinates (src) got determined as previously mentioned of the vertices of each plane. To become now the plane view, the destination coordinates of those vertices need to be calculated. This was done by creating a rectangle using the vertex coordinates and the ratios of the objects edges. After that those parameter got used to transform the image and cut off the surrounding unnecessary and distorted pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/man-transformation.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/man-transformation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This transformation can lead to distortions if there is another object on the corresponding plane. In the example below, there is an ear plug on top of the book cover. It can be seen, that the plug got wrapped by the transformation. So the transformation of object planes just works well on plain surfaces without other objects on top of it or other view restrictions (e.g. chimney on a roof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/distortion-plug.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/distortion-plug.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "After the transformation, the numpy-stl library got used to create a stl file, which later can be used for a 3D suite e.g. Blender to process the created 3D object further (map the image planes to the object). The code bellow shows that first the vertices of the object need to be created. This was done by manually defining vertices corresponding to the edge length of the real object. After that, the vertices need to get connected to form a surface, this was done by using triangles. Therefore, the faces array contains the 3 numbers of the vertices which form the face. At last a 3D mesh got created and stored to the stl-file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the 8 vertices of the cube, corresponding to the ratios of the real object\n",
    "vertices = np.array([\n",
    "    [-1, -1, -1],\n",
    "    [+55, -1, -1],\n",
    "    [+55, +190, -1],\n",
    "    [-1, +190, -1],\n",
    "    [-1, -1, +266],\n",
    "    [+55, -1, +266],\n",
    "    [+55, +190, +266],\n",
    "    [-1, +190, +266]])\n",
    "# Define the 12 triangles composing the cube\n",
    "faces = np.array([\n",
    "    [0, 3, 1],\n",
    "    [1, 3, 2],\n",
    "    [0, 4, 7],\n",
    "    [0, 7, 3],\n",
    "    [4, 5, 6],\n",
    "    [4, 6, 7],\n",
    "    [5, 1, 2],\n",
    "    [5, 2, 6],\n",
    "    [2, 3, 6],\n",
    "    [3, 7, 6],\n",
    "    [0, 1, 5],\n",
    "    [0, 5, 4]])\n",
    "\n",
    "# Create the mesh\n",
    "cube = mesh.Mesh(np.zeros(faces.shape[0], dtype=mesh.Mesh.dtype))\n",
    "for i, f in enumerate(faces):\n",
    "    for j in range(3):\n",
    "        cube.vectors[i][j] = vertices[f[j], :]\n",
    "\n",
    "# Write the mesh to file \"cube.stl\"\n",
    "cube.save('cube.stl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This stl-file now can be opened with blender. To map the previous determined object planes to the corresponding images, the following steps are necessary:\n",
    "1. Open the file in Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/blender-plain.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/blender-plain.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "2. Create a material for each object plane\n",
    "3. Select a face and assign it to the right material\n",
    "4. Change the **Base Color** to the image of the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/blender-assign.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/blender-assign.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "5. It is then possible to adjust the image (since the object ratios match to the image ratios, no further adjustment was needed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"report-images/blender-mapped.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url= \"report-images/blender-mapped.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Conclusion of the Classic Approach\n",
    "\n",
    "In the recent approach it was found out that it is possible to create a 3D object using just a single input image. However, the process cannot be fully automated and the user needs to specify additional lines, the object ratios and angles manually. The image transformation to object planes also has limitations, as further objects in the scene can distort the image, and the view/angle is crucial for obtaining the desired result.\n",
    "\n",
    "The success of the process is highly dependent on the complexity of the object being reconstructed. It was time-consuming and will definitely become more challenging for reconstructing complex objects. So the provided source code in the Classic-Approach/ folder just works for the given book image. For other objects the code or rather the points and ratios need to be recalculated and measured.\n",
    "\n",
    "Furthermore, the presented approach is suitable for simple objects, more complex objects would require alternative techniques like ToF or structured light to enhance accuracy and performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
